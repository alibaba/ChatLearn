runtime_env:
    platform: DLC
    excludes:
        - "*pt"
        - "logs"
        - "tensorboards"
        - ".nfs*"
models:
    policy:
        model_config_file: old_policy_inference.yaml
        num_device: ${num_device:8}
        trainable: False
        batch_generation:
            ranking: ${batch_generation_ranking:False}
            num_max_tokens: ${batch_generation_num_max_tokens:0}
            min_prompt_length: ${batch_generation_min_prompt_length:0}
rlhf:
    generation_batch_size: ${generation_batch_size:4}
    query_key: ${query_key:query}
    data_path: ${data_path:/path/to/data}
    eval_data_path: ${eval_data_path:/path/to/eval_data}
    eval_output_dir: ${eval_output_dir:/path/to/eval_dir}
