includes:
        - base_inference.yaml
        - reward_shared.yaml

tokenizer_type: GPT2BPETokenizer
ppo_tokenizer_type: GPT2BPETokenizer
ppo_vocab_file: tokenizer.json
reward_bias: 0

save_inference: False
save_inference_interval: 100
pipeline_model_parallel_size: ${reward_pp:1}
inference_batch_times_seqlen_threshold: ${inference_batch_times_seqlen_threshold:16384}