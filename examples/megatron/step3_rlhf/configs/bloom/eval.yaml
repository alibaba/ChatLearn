runtime_env:
  platform: DLC
  excludes:
    - "*pt"
    - "logs"
    - "tensorboards"
    - ".nfs*"


models:
  policy:
    model_config_file: old_policy_inference.yaml
    num_device: ${num_device:4}
    gpu_per_process: 1
    trainable: False
    
  reward:
    model_config_file: reward_inference.yaml
    num_device: ${num_device:4}
    gpu_per_process: 1
    trainable: False

rlhf:
  colocation:
    - policy,reward
  generation_batch_size: ${generation_batch_size:4}
  data_path: 