runtime_env:
  platform: DLC
  excludes:
    - "*pt"
    - "logs"
    - "tensorboards"
    - ".nfs*"


models:
  reward:
    model_config_file: reward_inference.yaml
    num_gpu: ${reward_device:1}
    gpu_per_process: 1
    trainable: False
runtime:
  generation_batch_size: ${generation_batch_size:4}
  eval_data_path: ${eval_data_path}
  exp_name: ${exp_name:chatlearn}