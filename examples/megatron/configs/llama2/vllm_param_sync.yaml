runtime_env:
  platform: DLC
  excludes:
    - "*pt"
    - "logs"
    - "tensorboards"
    - ".nfs*"


models:
  policy:
    model_config_file: vllm_policy_inference.yaml
    num_gpu: ${num_gpu_policy:16}
    trainable: False
    batch_generation:
      ranking: ${batch_generation_ranking:False}
      min_prompt_length: ${batch_generation_min_prompt_length:0}
    free_memory: ${free_memory_policy:False}

  ppo_policy:
    model_config_file: ppo_policy.yaml
    num_gpu: ${num_gpu_ppo_policy:16}
    trainable: True
    lora:
      enable_lora: ${enable_lora_policy:False}
      lora_dim: 64
      lora_layer: ColumnParallelLinear,LinearLayer,RowParallelLinear
      column_only_qkv: False
      lora_dropout: 0.05
    free_memory: ${free_memory_ppo_policy:False}

runtime:
  colocation:
    - policy
    - ppo_policy
  generation_batch_size: ${generation_batch_size:4}
  train_micro_batch_size: ${train_micro_batch_size:2}
  train_global_batch_size: ${train_global_batch_size:512}
  num_episode: ${num_episode:200}
  sample_per_episode: ${sample_per_episode:1024}
  num_training_epoch: 1
  save_episode_interval: ${save_episode_interval:50}
  data_path: ${data_path}
  eval_data_path: ${eval_data_path}
  training_data_num_limit: ${training_data_num_limit:-1}
  eval_data_num_limit: ${eval_data_num_limit:128}
  eval_episode_interval: ${eval_episode_interval:100}
  data_checkpoint_path: ${data_checkpoint_path}
  output_dir: ${output_dir}
  exp_name: ${exp_name:chatlearn}
  debug: ${debug:False}
  validate_param_sync: ${validate_param_sync:False}
  param_sync_comm_type: ${param_sync_comm_type:broadcast}
