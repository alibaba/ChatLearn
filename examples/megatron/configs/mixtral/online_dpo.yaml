runtime_env:
  platform: DLC
  excludes:
    - "*pt"
    - "logs"
    - "tensorboards"
    - ".nfs*"


models:
  policy:
    model_config_file: old_policy_inference.yaml
    num_gpu: ${num_gpu_policy:16}
    trainable: False
    batch_generation:
      ranking: ${batch_generation_ranking:False}
      min_prompt_length: ${batch_generation_min_prompt_length:0}
    free_memory: ${free_memory_policy:False}

  reference:
    model_config_file: reference.yaml
    num_gpu: ${num_gpu_ref:16}
    trainable: False
    generation_batch_size: ${ref_generation_batch_size:4}
    free_memory: ${free_memory_reference:False}

  reward:
    model_config_file: reward_inference.yaml
    num_gpu: ${num_gpu_reward:16}
    trainable: False
    free_memory: ${free_memory_reward:False}

  ppo_policy:
    model_config_file: ppo_policy.yaml
    num_gpu: ${num_gpu_ppo_policy:16}
    trainable: True
    lora:
      enable_lora: ${enable_lora_policy:False}
      lora_dim: 64
      lora_layer: ColumnParallelLinear,LinearLayer,RowParallelLinear
      column_only_qkv: False
      lora_dropout: 0.05
    free_memory: ${free_memory_ppo_policy:False}

runtime:
  colocation:
    - policy,ppo_policy,reward,reference
  generation_batch_size: ${generation_batch_size:4}
  train_micro_batch_size: ${train_micro_batch_size:2}
  train_global_batch_size: ${train_global_batch_size:512}
  num_episode: ${num_episode:200}
  sample_per_episode: ${sample_per_episode:1024}
  num_training_epoch: 1
  save_episode_interval: ${save_episode_interval:100}
  data_path: ${data_path}
  training_data_num_limit: ${training_data_num_limit:-1}
  eval_data_num_limit: ${eval_data_num_limit:128}
  eval_episode_interval: ${eval_episode_interval:100}
  data_checkpoint_path: ${data_checkpoint_path}
  output_dir: ${output_dir}
  free_sync_collective_group: ${free_sync_collective_group:False}
  exp_name: ${exp_name:chatlearn}
