# docker build -t your_docker_image -f Dockerfile.torch2.3.0 .
FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-devel

LABEL com.nvidia.volumes.needed="nvidia_driver"
LABEL com.nvidia.cuda.version=
ENV NVIDIA_VISIBLE_DEVICES= \
    NVIDIA_REQUIRE_CUDA="cuda>=11.0" \
    LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib:/usr/local/cuda/lib64

# install common libs
RUN pip install --no-cache-dir -U \
    ray[default]==2.32.0 \
    transformers==4.42.0 \
    pynvml==11.4.1 \
    deepspeed==0.14.4 \
    vllm==0.5.1 \
    jsonlines \
    torchtyping \
    tensorboard \
    cupy

# intall apex
RUN apt-get update && apt-get install git vim -y
WORKDIR /tmp/third_party
RUN git clone https://github.com/NVIDIA/apex
WORKDIR /tmp/third_party/apex
RUN pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings "--build-option=--cpp_ext" --config-settings "--build-option=--cuda_ext" ./
RUN rm -rf /tmp/third_party

# install transformer engine v1.2.1
RUN MAX_JOBS=4 pip install git+https://github.com/NVIDIA/TransformerEngine.git@v1.2.1

# env
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib64 \
    CUDA_DEVICE_MAX_CONNECTIONS=1
